1. \textbf{Frozen Feature Augmentation for Few-Shot Image Classification}\\\n   \textit{Andreas Bär, Neil Houlsby, Mostafa Dehghani, Manoj Kumar}\\\n   Computer Vision and Pattern Recognition (CVPR), 2024\\\n\vspace{0.3em}\n2. \textbf{Gemini: A Family of Highly Capable Multimodal Models}\\\n   \textit{Gemini Team Google}\\\n   arXiv, 2023\\\n\vspace{0.3em}\n3. \textbf{Scaling Laws for Sparsely-Connected Foundation Models}\\\n   \textit{Elias Frantar, Carlos Riquelme, Neil Houlsby, Dan Alistarh, Utku Evci}\\\n   International Conference on Learning Representations (ICLR), 2024 [spotlight]\\\n\vspace{0.3em}\n4. \textbf{From Sparse to Soft Mixtures of Experts}\\\n   \textit{Joan Puigcerver, Carlos Riquelme, Basil Mustafa, Neil Houlsby}\\\n   International Conference on Learning Representations (ICLR), 2024 [spotlight]\\\n\vspace{0.3em}\n6. \textbf{Scaling Open-Vocabulary Object Detection}\\\n   \textit{Scaling Open-Vocabulary Object Detection}\\\n   Neural Information Processing Systems (NeurIPS), 2022 [spotlight]\\\n\vspace{0.3em}\n7. \textbf{Image Captioners Are Scalable Vision Learners Too}\\\n   \textit{Michael Tschannen, Manoj Kumar, Andreas Steiner, Xiaohua Zhai, Neil Houlsby, Lucas Beyer}\\\n   Neural Information Processing Systems (NeurIPS), 2023 [oral]\\\n\vspace{0.3em}\n8. \textbf{PaLI-X: On Scaling up a Multilingual Vision and Language Model}\\\n   \textit{Xi Chen et al.}\\\n   Computer Vision and Pattern Recognition (CVPR), 2024\\\n\vspace{0.3em}\n9. \textbf{Scaling Vision Transformers to 22 Billion Parameters}\\\n   \textit{Mostafa Dehghani et al.}\\\n   International Conference on Machine Learning (ICML), 2023 [oral]\\\n\vspace{0.3em}\n10. \textbf{Dual PatchNorm}\\\n   \textit{Manoj Kumar, Mostafa Dehghani, Neil Houlsby}\\\n   Transactions on Machine Learning Research (TMLR)\\\n\vspace{0.3em}\n11. \textbf{Adaptive Computation with Elastic Input Sequence}\\\n   \textit{Fuzhao Xue, Valerii Likhosherstov, Anurag Arnab, Neil Houlsby, Mostafa Dehghani, Yang You}\\\n   International Conference on Machine Learning (ICML), 2023\\\n\vspace{0.3em}\n12. \textbf{Massively Scaling Heteroscedastic Classifiers}\\\n   \textit{Mark Collier, Rodolphe Jenatton, Basil Mustafa, Neil Houlsby, Jesse Berent, Effrosyni Kokiopoulou}\\\n   International Conference on Learning Representations (ICLR), 2023\\\n\vspace{0.3em}\n13. \textbf{CLIPPO: Image-and-Language Understanding from Pixels Only}\\\n   \textit{Michael Tschannen, Basil Mustafa, Neil Houlsby}\\\n   Computer Vision and Pattern Recognition (CVPR), 2023\\\n\vspace{0.3em}\n14. \textbf{Sparse Upcycling: Training Mixture-of-Experts from Dense Checkpoints}\\\n   \textit{Aran Komatsuzaki, Joan Puigcerver, James Lee-Thorp, Carlos Riquelme Ruiz, Basil Mustafa, Joshua Ainslie, Yi Tay, Mostafa Dehghani, Neil Houlsby}\\\n   International Conference on Learning Representations (ICLR), 2023\\\n\vspace{0.3em}\n15. \textbf{Location-Aware Self-Supervised Transformers for Semantic Segmentation}\\\n   \textit{Mathilde Caron, Neil Houlsby, Cordelia Schmid}\\\n   IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2023 [oral]\\\n\vspace{0.3em}\n16. \textbf{Transcending Scaling Laws with 0.1\% Extra Compute}\\\n   \textit{Yi Tay et al.}\\\n   Conference on Empirical Methods in Natural Language Processing (EMNLP), 2023\\\n\vspace{0.3em}\n17. \textbf{PaLI: A Jointly-Scaled Multilingual Language-Image Model}\\\n   \textit{Xi Chen et al.}\\\n   International Conference on Learning Representations (ICLR), 2023 [notable-top-5\%]\\\n\vspace{0.3em}\n18. \textbf{Multimodal Contrastive Learning with LIMoE: the Language-Image Mixture of Experts}\\\n   \textit{Basil Mustafa, Carlos Riquelme, Joan Puigcerver, Rodolphe Jenatton, Neil Houlsby}\\\n   Neural Information Processing Systems (NeurIPS), 2022\\\n\vspace{0.3em}\n19. \textbf{UViM: A Unified Modeling Approach for Vision with Learned Guiding Codes}\\\n   \textit{Alexander Kolesnikov, André Susano Pinto, Lucas Beyer, Xiaohua Zhai, Jeremiah Harmsen, Neil Houlsby}\\\n   Neural Information Processing Systems (NeurIPS), 2022\\\n\vspace{0.3em}\n20. \textbf{Robust and Efficient Medical Imaging with Self-Supervision}\\\n   \textit{Shekoofeh Azizi et al.}\\\n   Nature Biomedical Engineering\\\n\vspace{0.3em}\n21. \textbf{Simple Open-Vocabulary Object Detection with Vision Transformers}\\\n   \textit{Matthias Minderer et al.}\\\n   European Conference on Computer Vision (ECCV), 2020\\\n\vspace{0.3em}\n22. \textbf{Unifying Language Learning Paradigms}\\\n   \textit{Yi Tay, Mostafa Dehghani, Vinh Q. Tran, Xavier Garcia, Dara Bahri, Tal Schuster, Huaixiu Steven Zheng, Neil Houlsby, Donald Metzler}\\\n   International Conference on Learning Representations (ICLR), 2023\\\n\vspace{0.3em}\n23. \textbf{Do better ImageNet classifiers assess perceptual similarity better?}\\\n   \textit{Manoj Kumar, Neil Houlsby, Nal Kalchbrenner, Ekin Cubuk}\\\n   Transactions on Machine Learning Research (TMLR)\\\n\vspace{0.3em}\n24. \textbf{Learning to Merge Tokens in Vision Transformers}\\\n   \textit{Cedric Renggli, André Susano Pinto, Neil Houlsby, Basil Mustafa, Joan Puigcerver, Carlos Riquelme}\\\n   arXiv, 2022\\\n\vspace{0.3em}\n25. \textbf{Sparse MoEs meet Efficient Ensembles}\\\n   \textit{James Urquhart Allingham et al.}\\\n   Transactions on Machine Learning Research (TMLR)\\\n\vspace{0.3em}\n26. \textbf{The Benchmark Lottery}\\\n   \textit{Mostafa Dehghani, Yi Tay, Alexey A. Gritsenko, Zhe Zhao, Neil Houlsby, Fernando Diaz, Donald Metzler, Oriol Vinyals}\\\n   arXiv, 2021\\\n\vspace{0.3em}\n27. \textbf{Revisiting the Calibration of Modern Neural Networks}\\\n   \textit{Matthias Minderer, Josip Djolonga, Rob Romijnders, Frances Hubis, Xiaohua Zhai, Neil Houlsby, Dustin Tran, Mario Lucic}\\\n   Neural Information Processing Systems (NeurIPS), 2021\\\n\vspace{0.3em}\n28. \textbf{Scaling Vision with Sparse Mixture of Experts}\\\n   \textit{Carlos Riquelme, Joan Puigcerver, Basil Mustafa, Maxim Neumann, Rodolphe Jenatton, André Susano Pinto, Daniel Keysers, Neil Houlsby}\\\n   Neural Information Processing Systems (NeurIPS), 2021\\\n\vspace{0.3em}\n29. \textbf{Scaling Vision Transformers}\\\n   \textit{Xiaohua Zhai, Alexander Kolesnikov, Neil Houlsby, Lucas Beyer}\\\n   Computer Vision and Pattern Recognition (CVPR), 2022\\\n\vspace{0.3em}\n30. \textbf{SI-Score: An image dataset for fine-grained analysis of robustness to object location, rotation and size}\\\n   \textit{Jessica Yung, Rob Romijnders, Alexander Kolesnikov, Lucas Beyer, Josip Djolonga, Neil Houlsby, Sylvain Gelly, Mario Lucic, Xiaohua Zhai}\\\n   International Conference on Learning Represenations RobustML Workshop, 2021\\\n\vspace{0.3em}\n31. \textbf{MLP-Mixer: An all-MLP Architecture for Vision}\\\n   \textit{Ilya Tolstikhin, Neil Houlsby, Alexander Kolesnikov, Lucas Beyer, Xiaohua Zhai, Thomas Unterthiner, Jessica Yung, Andreas Steiner, Daniel Keysers, Jakob Uszkoreit, Mario Lucic, Alexey Dosovitskiy}\\\n   Neural Information Processing Systems (NeurIPS)\\\n\vspace{0.3em}\n32. \textbf{Comparing Transfer and Meta Learning Approaches on a Unified Few-Shot Classification Benchmark}\\\n   \textit{Vincent Dumoulin, Neil Houlsby, Utku Evci, Xiaohua Zhai, Ross Goroshin, Sylvain Gelly, Hugo Larochelle}\\\n   Neural Information Processing Systems Datasets and Benchmarks Track, 2021\\\n\vspace{0.3em}\n33. \textbf{Supervised Transfer Learning at Scale for Medical Imaging}\\\n   \textit{Basil Mustafa et al.}\\\n   arXiv, 2021\\\n\vspace{0.3em}\n35. \textbf{An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}\\\n   \textit{Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby}\\\n   International Conference on Learning Representations (ICLR), 2021\\\n\vspace{0.3em}\n36. \textbf{Deep Ensembles for Low-Data Transfer Learning}\\\n   \textit{Basil Mustafa, Carlos Riquelme, Joan Puigcerver, André Susano Pinto, Daniel Keysers, Neil Houlsby}\\\n   arXiv, 2020\\\n\vspace{0.3em}\n37. \textbf{Representation Learning From Videos In-the-Wild: An Object-Centric Approach}\\\n   \textit{Rob Romijnders, Aravindh Mahendran, Michael Tschannen, Josip Djolonga, Marvin Ritter, Neil Houlsby, Mario Lucic}\\\n   IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2021\\\n\vspace{0.3em}\n38. \textbf{Training General Representations for Remote Sensing Using In-Domain Knowledge}\\\n   \textit{Maxim Neumann, Andre Susano Pinto, Xiaohua Zhai, Neil Houlsby}\\\n   IEEE International Geoscience and Remote Sensing Symposium (IGARSS), 2020\\\n\vspace{0.3em}\n39. \textbf{Scalable Transfer Learning with Expert Models}\\\n   \textit{Joan Puigcerver, Carlos Riquelme, Basil Mustafa, Cedric Renggli, André Susano Pinto, Sylvain Gelly, Daniel Keysers, Neil Houlsby}\\\n   International Conference on Learning Representations (ICLR), 2021\\\n\vspace{0.3em}\n41. \textbf{Automatic Shortcut Removal for Self-Supervised Representation Learning}\\\n   \textit{Matthias Minderer, Olivier Bachem, Neil Houlsby, Michael Tschannen}\\\n   International Conference on Machine Learning (ICML), 2020\\\n\vspace{0.3em}\n42. \textbf{Big Transfer (BiT): General Visual Representation Learning}\\\n   \textit{Alexander Kolesnikov, Lucas Beyer, Xiaohua Zhai, Joan Puigcerver, Jessica Yung, Sylvain Gelly, Neil Houlsby}\\\n   European Conference on Computer Vision (ECCV), 2020\\\n\vspace{0.3em}\n43. \textbf{Self-Supervised Learning of Video-Induced Visual Invariances}\\\n   \textit{Michael Tschannen, Josip Djolonga, Marvin Ritter, Aravindh Mahendran, Xiaohua Zhai, Neil Houlsby, Sylvain Gelly, Mario Lucic}\\\n   Computer Vision and Pattern Recognition (CVPR), 2020\\\n\vspace{0.3em}\n44. \textbf{A Large-scale Study of Representation Learning with the Visual Task Adaptation Benchmark}\\\n   \textit{Xiaohua Zhai et al.}\\\n   arXiv, 2019\\\n\vspace{0.3em}\n45. \textbf{Parameter-Efficient Transfer Learning for NLP}\\\n   \textit{Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea Gesmundo, Mona Attariyan, Sylvain Gelly}\\\n   International Conference on Machine Learning (ICML), 2019\\\n\vspace{0.3em}\n46. \textbf{Neural Architecture Search Over a Graph Search Space}\\\n   \textit{Stanisław Jastrzębski, Quentin de Laroussilhe, Mingxing Tan, Xiao Ma, Neil Houlsby, Andrea Gesmundo}\\\n   arXiv, 2018\\\n\vspace{0.3em}\n47. \textbf{Self-Supervised GANs via Auxiliary Rotation Loss}\\\n   \textit{Ting Chen, Xiaohua Zhai, Marvin Ritter, Mario Lucic, Neil Houlsby}\\\n   Computer Vision and Pattern Recognition (CVPR), 2019\\\n\vspace{0.3em}\n48. \textbf{On Self Modulation for Generative Adversarial Networks}\\\n   \textit{Ting Chen, Mario Lucic, Neil Houlsby, Sylvain Gelly}\\\n   International Conference on Learning Representations (ICLR), 2019\\\n\vspace{0.3em}\n49. \textbf{Transfer Learning with Neural AutoML}\\\n   \textit{Catherine Wong, Neil Houlsby, Yifeng Lu, Andrea Gesmundo}\\\n   Neural Information Processing Systems (NeurIPS), 2018\\\n\vspace{0.3em}\n50. \textbf{Ask the Right Questions: Active Question Reformulation with Reinforcement Learning}\\\n   \textit{Christian Buck, Jannis Bulian, Massimiliano Ciaramita, Wojciech Gajewski, Andrea Gesmundo, Neil Houlsby, Wei Wang}\\\n   International Conference on Learning Representations (ICLR), 2018 [Oral]\\\n\vspace{0.3em}\n51. \textbf{A Filtering Approach to Stochastic Variational Inference}\\\n   \textit{Neil Houlsby, David Blei}\\\n   Neural Information Processing Systems (NeurIPS), 2014\\\n\vspace{0.3em}\n52. \textbf{Efficient Bayesian Active Learning and Matrix Modelling}\\\n   \textit{Neil Houlsby}\\\n   Doctor of Philosophy (PhD), University of Cambridge\\\n\vspace{0.3em}\n53. \textbf{Cold-start Active Learning with Robust Ordinal Matrix Factorization}\\\n   \textit{Cold-start Active Learning with Robust Ordinal Matrix Factorization}\\\n   International Conference on Machine Learning (ICML), 2014\\\n\vspace{0.3em}\n54. \textbf{Probabilistic Matrix Factorization with Non-random Missing Data}\\\n   \textit{José Miguel Hernández-Lobato, Neil Houlsby, Zoubin Ghahramani}\\\n   International Conference on Machine Learning (ICML)\\\n\vspace{0.3em}\n55. \textbf{Stochastic Inference for Scalable Probabilistic Modeling of Binary Matrices}\\\n   \textit{José Miguel Hernández-Lobato, Neil Houlsby, Zoubin Ghahramani}\\\n   International Conference on Machine Learning (ICML), 2021\\\n\vspace{0.3em}\n56. \textbf{Statistical Fitting of Undrained Strength Data}\\\n   \textit{Neil Houlsby, Guy Houlsby}\\\n   Géotechnique\\\n\vspace{0.3em}\n57. \textbf{Cognitive Tomography Reveals Complex Task-Independent Mental Representations}\\\n   \textit{Neil Houlsby, Ferenc Huszár, Mohammad Ghassemi, Gergő Orbán, Daniel Wolpert, Máté Lengyel}\\\n   Current Biology\\\n\vspace{0.3em}\n58. \textbf{A Scalable Gibbs Sampler for Probabilistic Entity Linking}\\\n   \textit{Neil Houlsby, Massimiliano Ciaramita}\\\n   European Conference on Information Retrieval (ECIR), 2014\\\n\vspace{0.3em}\n59. \textbf{Active learning for Interactive Visualization}\\\n   \textit{Tomoharu Iwata, Neil Houlsby, Zoubin Ghahramani}\\\n   International Conference on AI and Statistics (AISTATS), 2013\\\n\vspace{0.3em}\n60. \textbf{Experimental Adaptive Bayesian Tomography}\\\n   \textit{Konstantin Kravtsov, Stanislav Straupe, Igor Radchenko, Gleb Struchalin, Neil Houlsby, Sergey Kulik}\\\n   Phyiscal Review A\\\n\vspace{0.3em}\n61. \textbf{Collaborative Gaussian Processes for Preference Learning}\\\n   \textit{Neil Houlsby, Ferenc Huszár, Jose M. Hernández-lobato, Zoubin Ghahramani}\\\n   Neural Information Processing Systems (NeurIPS), 2012\\\n\vspace{0.3em}\n62. \textbf{Adaptive Bayesian Quantum Tomography}\\\n   \textit{Ferenc Huszár, Neil Houlsby}\\\n   Physical Review A\\\n\vspace{0.3em}\n63. \textbf{Bayesian Active Learning for Classification and Preference Learning}\\\n   \textit{Neil Houlsby, Ferenc Huszár, Zoubin Ghahramani, Máté Lengyel}\\\n   arXiv, 2011\\\n\vspace{0.3em}\n